{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIB: Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notation**\n",
    "* $x$ be our input source,\n",
    "* $y$ be our target\n",
    "* $z$ be our latent representation\n",
    "\n",
    "### Mutual Information\n",
    "Mutual information (MI) measures the amount of information obtained about one random variable after observing another random variable. Formally given two random variables $x$ and $y$ with joint distribution $p(x,y)$ and marginal densities $p(x)$ and $p(y)$ their MI is defined as the KL-divergence between the joint density and the product of their marginal densities\n",
    "$$\\begin{align}\n",
    "I(x;y)&=I(y;x)\\\\\n",
    "&=KL\\Big(p(x,y)||p(x)p(y)\\Big)\\\\\n",
    "&=\\mathbb{E}_{(x,y)\\sim p(x,y)}\\bigg[\\log\\frac{p(x,y)}{p(x)p(y)}\\bigg]\\\\\n",
    "&=\\int dxdyp(x,y)\\log\\frac{p(x,y)}{p(x)p(y)}\n",
    "\\end{align}$$\n",
    "\n",
    "### Information Bottlenecks\n",
    "IB regards supervised learning as a representation learning problem, seeking a stochastic map from input data\n",
    "$x$ to some latent representation $z$ that can still be used to predict the labels $y$ , under a constraint on its total complexity.\n",
    "\n",
    "We assume our joint distribution $p(x,y,z)$ can be factorised as follows:\n",
    "$$p(x,y,z)=p(z\\mid x,y)p(y\\mid x)p(x)=p(z\\mid x)p(y\\mid x)p(x)$$\n",
    "which corresponds to the following Markov Chain \n",
    "$$y\\rightarrow x\\rightarrow z$$\n",
    "\n",
    "Our goal is to learn an encoding that is maximally informative about our target $y$ measured by $I(y;z)$. We could always ensure a maximally informative representation by taking the identity encoding $x=z$ which is not useful. Instead we apply a constraint such that the objective is\n",
    "$$\\begin{alignat}{3}\n",
    "    &\\underset{}{\\text{max }} & \\quad & I(y;z)\\\\\n",
    "    &\\text{subject to } & \\quad & I(x;z)\\leq I_c\n",
    "\\end{alignat}$$\n",
    "where $I_c$ is the information constraint. The Lagrangian of the above constrained optimisation problem which we would like to **maximise** is \n",
    "$$\\begin{align}\n",
    "    L_{IB}&=I(y;z)-\\beta \\big(I(x;z)-I_c\\big)\\\\\n",
    "    &=I(y;z)-\\beta I(x;z)\n",
    "\\end{align}$$\n",
    "where $\\beta\\geq0$ is a Lagrange multiplier. \n",
    "* Intuitively the first term encourages $z$ to be predictive of $y$, whilst the second term encourages $z$ to \"forget\" $x$. \n",
    "* In essence, IB principle explicitly enforces the learned representation $z$ to only preserve the information in $x$ that is useful to the prediction of $y$, i.e., the minimal sufficient statistics of $x$ w.r.t. $y$.\n",
    "\n",
    "### Variational Information Bottlenecks\n",
    "\n",
    "**The first term**<br>\n",
    "We can write out the terms in the objective as\n",
    "$$I(y;z)=\\int dydz p(y,z)\\log \\frac{p(y,z)}{p(y)p(z)}=\\int dydz p(y,z)\\log \\frac{p(y\\mid z)}{p(y)}$$\n",
    "where $p(y\\mid z)$ is defined as\n",
    "$$p(y\\mid z)=\\int dx \\frac{p(x,y,z)}{p(z)}=\\int dx \\frac{p(z\\mid x)p(y\\mid x)p(x)}{p(z)}$$\n",
    "which is intractable. Let $q(y\\mid z)$ be a variational approximation to $p(y\\mid z)$. By using the KL divergence we can obtain a lower bound on $I(y;z)$\n",
    "$$KL\\Big(p(y\\mid z)|| q(y\\mid z)\\Big)\\geq0\\Longrightarrow \\int dy p(y\\mid z)\\log p(y\\mid z)\\geq \\int dy p(y\\mid z)\\log q(y\\mid z)$$\n",
    "Hence we have that \n",
    "$$\\begin{align}\n",
    "    I(y;z)&= \\int dydz p(y,z)\\log p(y\\mid z) - \\int dy p(y)\\log p(y)\\\\\n",
    "    &\\geq \\int dydz p(y, z)\\log q(y\\mid z) - \\int dy p(y)\\log p(y)\\\\\n",
    "    &=\\int dxdydz p(z\\mid x)p(y\\mid x)p(x)\\log q(y\\mid z)\n",
    "\\end{align}$$\n",
    "where the entropy of the labels $H(y)=- \\int dy p(y)\\log p(y)$ is independent of our optimisation and so can be ignored.\n",
    "\n",
    "\n",
    "**The second term**<br>\n",
    "We can write out the second term in the objective as \n",
    "$$I(x;z)=\\int dxdz p(x,z)\\log \\frac{p(x,z)}{p(x)p(z)}=\\int dxdz p(x,z)\\log \\frac{p(z\\mid x)}{p(z)}$$\n",
    "Let $q(z)$ be a variational approximation to the marginal $p(z)$. By using the KL divergence we can obtain an upper bound on $I(x;z)$ as \n",
    "$$KL\\Big(p(z)|| q(z)\\Big)\\geq0\\Longrightarrow \\int dz p(z)\\log p(z)\\geq \\int dz p(z)\\log q(z)$$\n",
    "Hence we have\n",
    "$$\\begin{align}\n",
    "    I(x;z)&=\\int dxdz p(x,z)\\log p(z\\mid x) - \\int dz p(z)\\log p(z)\\\\\n",
    "    &\\leq\\int dxdz p(x,z)\\log p(z\\mid x) - \\int dz p(z)\\log q(z)\\\\\n",
    "    &=\\int dxdz p(x)p(z\\mid x)\\log \\frac{p(z\\mid x)}{q(z)}\n",
    "\\end{align}$$\n",
    "\n",
    "### Loss Function\n",
    "Combining the above two bounds we can rewrite the Lagrangian which we would like to **maximise** as \n",
    "$$\\begin{align}\n",
    "    L_{IB}&=I(y;z)-\\beta I(x;z)\\\\\n",
    "    &\\geq \\int dxdydz p(z\\mid x)p(y\\mid x)p(x)\\log q(y\\mid z) -\\beta\\int dxdz p(x)p(z\\mid x)\\log \\frac{p(z\\mid x)}{q(z)}\\\\\n",
    "    &=\\int dxdydz p(z\\mid x)p(y,x)\\log q(y\\mid z) -\\beta\\int dxdydz p(z\\mid x)p(x,y)KL\\Big(p(z\\mid x)||q(z)\\Big)\\\\\n",
    "    &=\\mathbb{E}_{(x,y)\\sim p(x,y), z\\sim p(z\\mid x)}\\bigg[\\log q(y\\mid z)-\\beta KL\\Big(p(z\\mid x)||q(z)\\Big)\\bigg]\\\\\n",
    "    &=J_{IB}\n",
    "\\end{align}$$\n",
    "\n",
    "To compute the lower bound in practice make the following assumptions:\n",
    "\n",
    "* We approximate $p(x,y)=p(x)p(y\\mid x)$ using the empirical data distribution $p(x,y)=\\frac{1}{n}\\sum^{n}_{i=1}\\delta_{x_i}(x)\\delta_{y_i}(y)$ such that \n",
    "$$\\begin{align}\n",
    "J_{IB}&= \\int dxdydz p(z\\mid x)p(y\\mid x)p(x)\\log q(y\\mid z) -\\beta\\int dxdz p(x)p(z\\mid x)\\log \\frac{p(z\\mid x)}{q(z)}\\\\\n",
    "&\\approx \\frac{1}{n}\\sum^{n}_{i=1}\\bigg[\\int dz p(z\\mid x_i)\\log q(y_i\\mid z)-\\beta\\int dz p(z\\mid x_i)\\log \\frac{p(z\\mid x_i)}{q(z)}\\bigg]\\\\\n",
    "&=\\frac{1}{n}\\sum^{n}_{i=1}\\bigg[\\int dz p(z\\mid x_i)\\log q(y_i\\mid z)- \\beta KL\\Big(p(z\\mid x_i)|| q(z)\\Big) \\bigg]\n",
    "\\end{align}$$\n",
    "\n",
    "* By using an encoder parameterised as multivariate Gaussian\n",
    "$$p_\\phi(z\\mid x)=\\mathcal{N}\\bigg(z;\\boldsymbol{\\mu}_\\phi(x), \\boldsymbol{\\Sigma}_\\phi(x)\\bigg)$$\n",
    "then we can use the reparameterisation trick such that $z=g_\\phi(\\epsilon,x)$ which is a deterministic function of $x$ and the Gaussian random variable $\\epsilon\\sim p(\\epsilon)=\\mathcal{N}(0,I)$.\n",
    "\n",
    "* We assume that our choice of parameterisation of $p(z\\mid x)$ and $q(z)$ allow for computation of an analytic KL-divergence, \n",
    "\n",
    "Thus the final objective we would **minimise** is \n",
    "$$J_{IB}=\\frac{1}{n}\\sum^{n}_{i=1}\\Bigg[\\beta KL\\Big(p(z\\mid x_i)|| q(z)\\Big) - \\mathbb{E}_{\\epsilon\\sim p(\\epsilon)}\\Big[\\log q\\big(y_i\\mid g_\\phi(\\epsilon,x)\\big)\\Big]\\Bigg]$$\n",
    "where we have that \n",
    "* $p_\\phi(z\\mid x)$ is the encoder parameterised as a multivariate Gaussian \n",
    "$$p_\\phi(z\\mid x)=\\mathcal{N}\\bigg(z;\\boldsymbol{\\mu}_\\phi(x), \\boldsymbol{\\Sigma}_\\phi(x)\\bigg)$$\n",
    "* $q_\\theta(y\\mid z)$ is the decoder parameterised as an independent Bernoulli for each element $y_j$ of $y$ (for binary data) \n",
    "$$q_\\theta(y_j\\mid z)=\\text{Ber}\\Big(\\mu_\\theta(z)\\Big)$$\n",
    "* $q(z)$ is the approximated latent marginal often fixed to a standard normal.\n",
    "$$q_\\theta(z)=\\mathcal{N}\\Big(z;\\mathbf{0},\\mathbf{I}_k\\Big)$$\n",
    "\n",
    "By using our parameterisation of the decoder $q_\\theta(y\\mid z)$ as an indepenedent Bernoulli we have that \n",
    "$$-\\log q_\\theta(y\\mid z)=-\\Big[y\\log \\hat{y} + (1-y)\\log(1-\\hat{y})\\Big]$$\n",
    "i.e. this is the Binary Cross Entropy loss.\n",
    "\n",
    "### Connection to Variational Autoencoder\n",
    "The VAE is a special case of an unsupervised version of VIB with $\\beta=1.0$ as they consider the objective \n",
    "$$L=I(x;z)-\\beta I(i;z)$$\n",
    "where the aim is to take our data $x$ and maximise the mutual information contained in some encoding $z$, while restricting how much information we allow our representation to contain about the identity of each data element in our sample $i$. While this objective takes the same mathematical form as that of a Variational Autoencoder, the interpretation of the objective is very different:\n",
    "* In the VAE, the model starts life as a generative model with a defined prior $p(z)$ and stochastic decoder $p(x|z)$ as part of the model, and the encoder $q(z|x)$ is created to serve as a variational approximation to the true posterior $p(z|x) = \\frac{p(x|z)}{p(z)p(x)}$. \n",
    "* In the VIB approach, the model is originally just the stochastic encoder $p(z|x)$, and the decoder $q(x|z)$ is the variational approximation to the true $p(x|z) = \\frac{p(z|x)p(x)}{p(z)}$ and $q(z)$ is the variational approximation to the marginal $p(z) =\\int dx p(x)p(z|x)$.\n",
    "\n",
    "### References\n",
    "* Original Deep VIB paper: https://arxiv.org/abs/1612.00410"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIB: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is almost identical to my VAE implementation found here: [torch_vae](https://github.com/udeepam/vae/blob/master/notebooks/vae.ipynb)\n",
    "\n",
    "**References:**\n",
    "* https://github.com/makezur/VIB_pytorch\n",
    "* https://github.com/sungyubkim/DVIB\n",
    "* https://github.com/1Konny/VIB-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# Device Config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Fix random seeds for reproducibility\n",
    "seed = 73\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torchvision import transforms\n",
    "# from torchvision.datasets import MNIST\n",
    "# # 60000 tuples with 1x28x28 image and corresponding label\n",
    "# data = MNIST('data', \n",
    "#              train=True, \n",
    "#              download=True,\n",
    "#              transform = transforms.Compose([transforms.ToTensor()]))\n",
    "# # Split data into images and labels\n",
    "# x_train = data.train_data\n",
    "# y_train = data.train_labels\n",
    "# # Scale images from [0,255] to [0,+1]\n",
    "# x_train = x_train.float() / 255\n",
    "# # Save as .npz\n",
    "# np.savez_compressed('data/mnist_train', \n",
    "#                     a=x_train,\n",
    "#                     b=y_train)\n",
    "\n",
    "# # 10000 tuples with 1x28x28 image and corresponding label\n",
    "# data = MNIST('data', \n",
    "#              train=False, \n",
    "#              download=True,\n",
    "#              transform = transforms.Compose([transforms.ToTensor()]))\n",
    "# # Split data into images and labels\n",
    "# x_test = data.test_data\n",
    "# y_test = data.test_labels\n",
    "# # Scale images from [0,255] to [0,+1]\n",
    "# x_test = x_test.float() / 255\n",
    "# # Save as .npz\n",
    "# np.savez_compressed('data/mnist_test', \n",
    "#                     a=x_test,\n",
    "#                     b=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data locally\n",
    "train_data = np.load('data/mnist_train.npz')\n",
    "x_train = torch.Tensor(train_data['a'])\n",
    "y_train = torch.Tensor(train_data['b'])\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "test_data = np.load('data/mnist_test.npz')\n",
    "x_test = torch.Tensor(test_data['a'])\n",
    "y_test = torch.Tensor(test_data['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2520x2520 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise data\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, axes = plt.subplots(1,4, figsize=(35,35))\n",
    "imx, imy = (28,28)\n",
    "labels   = [0,1,2,3]\n",
    "for i, ax in enumerate(axes):\n",
    "    visual = np.reshape(x_train[labels[i]], (imx,imy))\n",
    "    ax.set_title(\"Example Data Image, y=\"+str(int(y_train[labels[i]])))\n",
    "    ax.imshow(visual, vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepVIB(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape, z_dim):\n",
    "        \"\"\"\n",
    "        Deep VIB Model.\n",
    "        \n",
    "        Arguments:\n",
    "        ----------\n",
    "        input_shape : `int`\n",
    "            Flattened size of image. (Default=784)\n",
    "        output_shape : `int`\n",
    "            Number of classes. (Default=10)            \n",
    "        z_dim : `int`\n",
    "            The dimension of the latent variable z. (Default=256)\n",
    "        \"\"\"        \n",
    "        super(DeepVIB, self).__init__()\n",
    "        self.input_shape  = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.z_dim  = z_dim\n",
    "        \n",
    "        # build encoder\n",
    "        self.encoder = nn.Sequential(nn.Linear(input_shape, 1024),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     nn.Linear(1024, 1024),\n",
    "                                     nn.ReLU(inplace=True)                                    )  \n",
    "        self.fc_mu  = nn.Linear(1024, self.z_dim) \n",
    "        self.fc_std = nn.Linear(1024, self.z_dim)\n",
    "        \n",
    "        # build decoder\n",
    "        self.decoder = nn.Linear(self.z_dim, output_shape)\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        x : [batch_size,784]\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        return self.fc_mu(x), F.softplus(self.fc_std(x)-5, beta=1)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        z : [batch_size,z_dim]\n",
    "        \"\"\" \n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def reparameterise(self, mu, std):\n",
    "        \"\"\"\n",
    "        mu : [batch_size,z_dim]\n",
    "        std : [batch_size,z_dim]        \n",
    "        \"\"\"        \n",
    "        # get epsilon from standard normal\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std*eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass \n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : [batch_size,28,28]\n",
    "        \"\"\"\n",
    "        # flattent image\n",
    "        x_flat = x.view(x.size(0), -1)\n",
    "        mu, std = self.encode(x_flat)\n",
    "        z = self.reparameterise(mu, std)\n",
    "        return self.decode(z), mu, std     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "beta   = 1e-3\n",
    "z_dim  = 256\n",
    "epochs = 200\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "DeepVIB(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc_mu): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (fc_std): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (decoder): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create DatatLoader \n",
    "train_dataset    = data_utils.TensorDataset(x_train, y_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "# Loss function: Cross Entropy Loss (CE) + beta*KL divergence\n",
    "def loss_function(y_pred, y, mu, std):\n",
    "    \"\"\"    \n",
    "    y_pred : [batch_size,10]\n",
    "    y : [batch_size,10]    \n",
    "    mu : [batch_size,z_dim]  \n",
    "    std: [batch_size,z_dim] \n",
    "    \"\"\"   \n",
    "    CE = F.cross_entropy(y_pred, y, reduction='sum')\n",
    "    KL = 0.5 * torch.sum(mu.pow(2) + std.pow(2) - 2*std.log() - 1)\n",
    "    return (beta*KL + CE) / y.size(0)\n",
    "\n",
    "# Initialize Deep VIB\n",
    "vib = DeepVIB(np.prod(x_train[0].shape), n_classes, z_dim)\n",
    "\n",
    "# Optimiser\n",
    "optimiser = torch.optim.Adam(vib.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimiser, gamma=decay_rate)\n",
    "\n",
    "# Send to GPU if available\n",
    "vib.to(device)\n",
    "\n",
    "print(\"Device: \", device)\n",
    "print(vib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200... Loss: 0.8247... Accuracy: 0.8544... Time Taken: 2.9338 seconds\n",
      "Epoch: 2/200... Loss: 0.3168... Accuracy: 0.9435... Time Taken: 2.6235 seconds\n",
      "Epoch: 3/200... Loss: 0.2235... Accuracy: 0.9614... Time Taken: 3.1089 seconds\n",
      "Epoch: 4/200... Loss: 0.1736... Accuracy: 0.9713... Time Taken: 2.7176 seconds\n",
      "Epoch: 5/200... Loss: 0.1419... Accuracy: 0.9778... Time Taken: 2.8584 seconds\n",
      "Epoch: 6/200... Loss: 0.1211... Accuracy: 0.9825... Time Taken: 2.6173 seconds\n",
      "Epoch: 7/200... Loss: 0.1039... Accuracy: 0.9865... Time Taken: 2.6863 seconds\n",
      "Epoch: 8/200... Loss: 0.0908... Accuracy: 0.9896... Time Taken: 2.6867 seconds\n",
      "Epoch: 9/200... Loss: 0.0811... Accuracy: 0.9913... Time Taken: 2.6113 seconds\n",
      "Epoch: 10/200... Loss: 0.0731... Accuracy: 0.9932... Time Taken: 3.1410 seconds\n",
      "Epoch: 11/200... Loss: 0.0650... Accuracy: 0.9948... Time Taken: 2.7592 seconds\n",
      "Epoch: 12/200... Loss: 0.0604... Accuracy: 0.9954... Time Taken: 2.6326 seconds\n",
      "Epoch: 13/200... Loss: 0.0557... Accuracy: 0.9961... Time Taken: 3.3420 seconds\n",
      "Epoch: 14/200... Loss: 0.0525... Accuracy: 0.9970... Time Taken: 2.6378 seconds\n",
      "Epoch: 15/200... Loss: 0.0486... Accuracy: 0.9973... Time Taken: 2.5848 seconds\n",
      "Epoch: 16/200... Loss: 0.0454... Accuracy: 0.9980... Time Taken: 2.5640 seconds\n",
      "Epoch: 17/200... Loss: 0.0442... Accuracy: 0.9976... Time Taken: 2.7317 seconds\n",
      "Epoch: 18/200... Loss: 0.0419... Accuracy: 0.9980... Time Taken: 2.6942 seconds\n",
      "Epoch: 19/200... Loss: 0.0395... Accuracy: 0.9984... Time Taken: 3.0209 seconds\n",
      "Epoch: 20/200... Loss: 0.0382... Accuracy: 0.9984... Time Taken: 2.6198 seconds\n",
      "Epoch: 21/200... Loss: 0.0366... Accuracy: 0.9986... Time Taken: 2.7759 seconds\n",
      "Epoch: 22/200... Loss: 0.0366... Accuracy: 0.9984... Time Taken: 2.7001 seconds\n",
      "Epoch: 23/200... Loss: 0.0337... Accuracy: 0.9990... Time Taken: 3.1175 seconds\n",
      "Epoch: 24/200... Loss: 0.0338... Accuracy: 0.9988... Time Taken: 2.7052 seconds\n",
      "Epoch: 25/200... Loss: 0.0327... Accuracy: 0.9990... Time Taken: 2.7418 seconds\n",
      "Epoch: 26/200... Loss: 0.0327... Accuracy: 0.9989... Time Taken: 3.0871 seconds\n",
      "Epoch: 27/200... Loss: 0.0315... Accuracy: 0.9990... Time Taken: 2.8472 seconds\n",
      "Epoch: 28/200... Loss: 0.0305... Accuracy: 0.9992... Time Taken: 3.4106 seconds\n",
      "Epoch: 29/200... Loss: 0.0309... Accuracy: 0.9989... Time Taken: 2.7489 seconds\n",
      "Epoch: 30/200... Loss: 0.0291... Accuracy: 0.9992... Time Taken: 2.6132 seconds\n",
      "Epoch: 31/200... Loss: 0.0287... Accuracy: 0.9992... Time Taken: 3.1964 seconds\n",
      "Epoch: 32/200... Loss: 0.0279... Accuracy: 0.9994... Time Taken: 2.7221 seconds\n",
      "Epoch: 33/200... Loss: 0.0274... Accuracy: 0.9994... Time Taken: 2.6423 seconds\n",
      "Epoch: 34/200... Loss: 0.0281... Accuracy: 0.9991... Time Taken: 2.9033 seconds\n",
      "Epoch: 35/200... Loss: 0.0274... Accuracy: 0.9991... Time Taken: 3.2232 seconds\n",
      "Epoch: 36/200... Loss: 0.0269... Accuracy: 0.9993... Time Taken: 3.1736 seconds\n",
      "Epoch: 37/200... Loss: 0.0262... Accuracy: 0.9994... Time Taken: 2.5905 seconds\n",
      "Epoch: 38/200... Loss: 0.0271... Accuracy: 0.9991... Time Taken: 3.3423 seconds\n",
      "Epoch: 39/200... Loss: 0.0260... Accuracy: 0.9993... Time Taken: 2.6030 seconds\n",
      "Epoch: 40/200... Loss: 0.0256... Accuracy: 0.9994... Time Taken: 2.6783 seconds\n",
      "Epoch: 41/200... Loss: 0.0257... Accuracy: 0.9992... Time Taken: 2.7412 seconds\n",
      "Epoch: 42/200... Loss: 0.0247... Accuracy: 0.9994... Time Taken: 3.0694 seconds\n",
      "Epoch: 43/200... Loss: 0.0255... Accuracy: 0.9991... Time Taken: 2.8609 seconds\n",
      "Epoch: 44/200... Loss: 0.0245... Accuracy: 0.9993... Time Taken: 2.8332 seconds\n",
      "Epoch: 45/200... Loss: 0.0247... Accuracy: 0.9994... Time Taken: 3.2771 seconds\n",
      "Epoch: 46/200... Loss: 0.0246... Accuracy: 0.9992... Time Taken: 2.6079 seconds\n",
      "Epoch: 47/200... Loss: 0.0241... Accuracy: 0.9994... Time Taken: 3.1023 seconds\n",
      "Epoch: 48/200... Loss: 0.0240... Accuracy: 0.9994... Time Taken: 2.9019 seconds\n",
      "Epoch: 49/200... Loss: 0.0237... Accuracy: 0.9993... Time Taken: 2.8837 seconds\n",
      "Epoch: 50/200... Loss: 0.0241... Accuracy: 0.9993... Time Taken: 3.3029 seconds\n",
      "Epoch: 51/200... Loss: 0.0235... Accuracy: 0.9995... Time Taken: 3.0055 seconds\n",
      "Epoch: 52/200... Loss: 0.0235... Accuracy: 0.9993... Time Taken: 2.7285 seconds\n",
      "Epoch: 53/200... Loss: 0.0236... Accuracy: 0.9993... Time Taken: 2.5974 seconds\n",
      "Epoch: 54/200... Loss: 0.0229... Accuracy: 0.9993... Time Taken: 2.9562 seconds\n",
      "Epoch: 55/200... Loss: 0.0231... Accuracy: 0.9994... Time Taken: 2.6335 seconds\n",
      "Epoch: 56/200... Loss: 0.0230... Accuracy: 0.9993... Time Taken: 2.6220 seconds\n",
      "Epoch: 57/200... Loss: 0.0229... Accuracy: 0.9992... Time Taken: 2.6912 seconds\n",
      "Epoch: 58/200... Loss: 0.0224... Accuracy: 0.9994... Time Taken: 2.8508 seconds\n",
      "Epoch: 59/200... Loss: 0.0220... Accuracy: 0.9995... Time Taken: 2.6053 seconds\n",
      "Epoch: 60/200... Loss: 0.0222... Accuracy: 0.9994... Time Taken: 2.5654 seconds\n",
      "Epoch: 61/200... Loss: 0.0220... Accuracy: 0.9995... Time Taken: 2.6095 seconds\n",
      "Epoch: 62/200... Loss: 0.0217... Accuracy: 0.9995... Time Taken: 2.6336 seconds\n",
      "Epoch: 63/200... Loss: 0.0217... Accuracy: 0.9995... Time Taken: 2.6273 seconds\n",
      "Epoch: 64/200... Loss: 0.0220... Accuracy: 0.9994... Time Taken: 3.3488 seconds\n",
      "Epoch: 65/200... Loss: 0.0221... Accuracy: 0.9994... Time Taken: 2.6145 seconds\n",
      "Epoch: 66/200... Loss: 0.0217... Accuracy: 0.9992... Time Taken: 2.8320 seconds\n",
      "Epoch: 67/200... Loss: 0.0214... Accuracy: 0.9994... Time Taken: 2.6069 seconds\n",
      "Epoch: 68/200... Loss: 0.0213... Accuracy: 0.9995... Time Taken: 2.5644 seconds\n",
      "Epoch: 69/200... Loss: 0.0208... Accuracy: 0.9996... Time Taken: 2.7144 seconds\n",
      "Epoch: 70/200... Loss: 0.0210... Accuracy: 0.9996... Time Taken: 2.9346 seconds\n",
      "Epoch: 71/200... Loss: 0.0211... Accuracy: 0.9995... Time Taken: 2.6813 seconds\n",
      "Epoch: 72/200... Loss: 0.0212... Accuracy: 0.9993... Time Taken: 2.6847 seconds\n",
      "Epoch: 73/200... Loss: 0.0211... Accuracy: 0.9995... Time Taken: 2.9722 seconds\n",
      "Epoch: 74/200... Loss: 0.0214... Accuracy: 0.9993... Time Taken: 2.6538 seconds\n",
      "Epoch: 75/200... Loss: 0.0207... Accuracy: 0.9997... Time Taken: 3.3534 seconds\n",
      "Epoch: 76/200... Loss: 0.0208... Accuracy: 0.9994... Time Taken: 2.6201 seconds\n",
      "Epoch: 77/200... Loss: 0.0204... Accuracy: 0.9996... Time Taken: 2.6122 seconds\n",
      "Epoch: 78/200... Loss: 0.0205... Accuracy: 0.9996... Time Taken: 2.5787 seconds\n",
      "Epoch: 79/200... Loss: 0.0207... Accuracy: 0.9994... Time Taken: 2.5820 seconds\n",
      "Epoch: 80/200... Loss: 0.0207... Accuracy: 0.9993... Time Taken: 2.6216 seconds\n",
      "Epoch: 81/200... Loss: 0.0204... Accuracy: 0.9994... Time Taken: 2.5788 seconds\n",
      "Epoch: 82/200... Loss: 0.0204... Accuracy: 0.9995... Time Taken: 3.0649 seconds\n",
      "Epoch: 83/200... Loss: 0.0202... Accuracy: 0.9996... Time Taken: 2.6127 seconds\n",
      "Epoch: 84/200... Loss: 0.0201... Accuracy: 0.9995... Time Taken: 2.5784 seconds\n",
      "Epoch: 85/200... Loss: 0.0200... Accuracy: 0.9995... Time Taken: 3.3494 seconds\n",
      "Epoch: 86/200... Loss: 0.0203... Accuracy: 0.9996... Time Taken: 3.3574 seconds\n",
      "Epoch: 87/200... Loss: 0.0199... Accuracy: 0.9995... Time Taken: 2.6292 seconds\n",
      "Epoch: 88/200... Loss: 0.0204... Accuracy: 0.9994... Time Taken: 3.3624 seconds\n",
      "Epoch: 89/200... Loss: 0.0205... Accuracy: 0.9993... Time Taken: 3.3769 seconds\n",
      "Epoch: 90/200... Loss: 0.0198... Accuracy: 0.9995... Time Taken: 2.5880 seconds\n",
      "Epoch: 91/200... Loss: 0.0194... Accuracy: 0.9996... Time Taken: 2.6509 seconds\n",
      "Epoch: 92/200... Loss: 0.0199... Accuracy: 0.9994... Time Taken: 2.8752 seconds\n",
      "Epoch: 93/200... Loss: 0.0197... Accuracy: 0.9996... Time Taken: 2.6407 seconds\n",
      "Epoch: 94/200... Loss: 0.0195... Accuracy: 0.9997... Time Taken: 2.8048 seconds\n",
      "Epoch: 95/200... Loss: 0.0196... Accuracy: 0.9995... Time Taken: 2.6742 seconds\n",
      "Epoch: 96/200... Loss: 0.0196... Accuracy: 0.9995... Time Taken: 2.6301 seconds\n",
      "Epoch: 97/200... Loss: 0.0193... Accuracy: 0.9996... Time Taken: 2.7376 seconds\n",
      "Epoch: 98/200... Loss: 0.0194... Accuracy: 0.9995... Time Taken: 2.6650 seconds\n",
      "Epoch: 99/200... Loss: 0.0197... Accuracy: 0.9995... Time Taken: 2.6346 seconds\n",
      "Epoch: 100/200... Loss: 0.0192... Accuracy: 0.9996... Time Taken: 2.7169 seconds\n",
      "Epoch: 101/200... Loss: 0.0194... Accuracy: 0.9995... Time Taken: 3.3288 seconds\n",
      "Epoch: 102/200... Loss: 0.0196... Accuracy: 0.9995... Time Taken: 3.3768 seconds\n",
      "Epoch: 103/200... Loss: 0.0196... Accuracy: 0.9995... Time Taken: 3.3494 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104/200... Loss: 0.0190... Accuracy: 0.9996... Time Taken: 2.6361 seconds\n",
      "Epoch: 105/200... Loss: 0.0189... Accuracy: 0.9996... Time Taken: 2.6597 seconds\n",
      "Epoch: 106/200... Loss: 0.0192... Accuracy: 0.9994... Time Taken: 2.6189 seconds\n",
      "Epoch: 107/200... Loss: 0.0192... Accuracy: 0.9996... Time Taken: 3.0845 seconds\n",
      "Epoch: 108/200... Loss: 0.0190... Accuracy: 0.9996... Time Taken: 2.6658 seconds\n",
      "Epoch: 109/200... Loss: 0.0190... Accuracy: 0.9996... Time Taken: 2.5523 seconds\n",
      "Epoch: 110/200... Loss: 0.0187... Accuracy: 0.9998... Time Taken: 2.9323 seconds\n",
      "Epoch: 111/200... Loss: 0.0189... Accuracy: 0.9996... Time Taken: 2.8170 seconds\n",
      "Epoch: 112/200... Loss: 0.0188... Accuracy: 0.9996... Time Taken: 2.5783 seconds\n",
      "Epoch: 113/200... Loss: 0.0191... Accuracy: 0.9995... Time Taken: 3.3629 seconds\n",
      "Epoch: 114/200... Loss: 0.0191... Accuracy: 0.9995... Time Taken: 2.6130 seconds\n",
      "Epoch: 115/200... Loss: 0.0189... Accuracy: 0.9996... Time Taken: 2.6526 seconds\n",
      "Epoch: 116/200... Loss: 0.0189... Accuracy: 0.9995... Time Taken: 4.0172 seconds\n",
      "Epoch: 117/200... Loss: 0.0190... Accuracy: 0.9996... Time Taken: 2.6815 seconds\n",
      "Epoch: 118/200... Loss: 0.0186... Accuracy: 0.9997... Time Taken: 2.5753 seconds\n",
      "Epoch: 119/200... Loss: 0.0186... Accuracy: 0.9996... Time Taken: 2.9361 seconds\n",
      "Epoch: 120/200... Loss: 0.0188... Accuracy: 0.9996... Time Taken: 2.6108 seconds\n",
      "Epoch: 121/200... Loss: 0.0186... Accuracy: 0.9996... Time Taken: 2.6475 seconds\n",
      "Epoch: 122/200... Loss: 0.0188... Accuracy: 0.9996... Time Taken: 3.3376 seconds\n",
      "Epoch: 123/200... Loss: 0.0182... Accuracy: 0.9997... Time Taken: 2.6128 seconds\n",
      "Epoch: 124/200... Loss: 0.0185... Accuracy: 0.9996... Time Taken: 2.7202 seconds\n",
      "Epoch: 125/200... Loss: 0.0185... Accuracy: 0.9995... Time Taken: 2.6614 seconds\n",
      "Epoch: 126/200... Loss: 0.0186... Accuracy: 0.9995... Time Taken: 2.6227 seconds\n",
      "Epoch: 127/200... Loss: 0.0185... Accuracy: 0.9996... Time Taken: 2.6026 seconds\n",
      "Epoch: 128/200... Loss: 0.0182... Accuracy: 0.9996... Time Taken: 2.6591 seconds\n",
      "Epoch: 129/200... Loss: 0.0184... Accuracy: 0.9996... Time Taken: 2.6267 seconds\n",
      "Epoch: 130/200... Loss: 0.0182... Accuracy: 0.9997... Time Taken: 2.6503 seconds\n",
      "Epoch: 131/200... Loss: 0.0183... Accuracy: 0.9996... Time Taken: 2.5881 seconds\n",
      "Epoch: 132/200... Loss: 0.0183... Accuracy: 0.9997... Time Taken: 2.8815 seconds\n",
      "Epoch: 133/200... Loss: 0.0185... Accuracy: 0.9996... Time Taken: 2.8744 seconds\n",
      "Epoch: 134/200... Loss: 0.0183... Accuracy: 0.9996... Time Taken: 2.5883 seconds\n",
      "Epoch: 135/200... Loss: 0.0180... Accuracy: 0.9996... Time Taken: 2.7730 seconds\n",
      "Epoch: 136/200... Loss: 0.0183... Accuracy: 0.9995... Time Taken: 2.6282 seconds\n",
      "Epoch: 137/200... Loss: 0.0181... Accuracy: 0.9996... Time Taken: 2.6488 seconds\n",
      "Epoch: 138/200... Loss: 0.0182... Accuracy: 0.9996... Time Taken: 3.1817 seconds\n",
      "Epoch: 139/200... Loss: 0.0182... Accuracy: 0.9996... Time Taken: 2.5606 seconds\n",
      "Epoch: 140/200... Loss: 0.0180... Accuracy: 0.9997... Time Taken: 2.6162 seconds\n",
      "Epoch: 141/200... Loss: 0.0182... Accuracy: 0.9996... Time Taken: 2.8601 seconds\n",
      "Epoch: 142/200... Loss: 0.0181... Accuracy: 0.9995... Time Taken: 2.6141 seconds\n",
      "Epoch: 143/200... Loss: 0.0181... Accuracy: 0.9996... Time Taken: 2.6489 seconds\n",
      "Epoch: 144/200... Loss: 0.0178... Accuracy: 0.9997... Time Taken: 2.5955 seconds\n",
      "Epoch: 145/200... Loss: 0.0178... Accuracy: 0.9997... Time Taken: 2.5702 seconds\n",
      "Epoch: 146/200... Loss: 0.0180... Accuracy: 0.9996... Time Taken: 3.3677 seconds\n",
      "Epoch: 147/200... Loss: 0.0181... Accuracy: 0.9996... Time Taken: 2.6410 seconds\n",
      "Epoch: 148/200... Loss: 0.0178... Accuracy: 0.9998... Time Taken: 2.7881 seconds\n",
      "Epoch: 149/200... Loss: 0.0183... Accuracy: 0.9995... Time Taken: 2.6617 seconds\n",
      "Epoch: 150/200... Loss: 0.0182... Accuracy: 0.9995... Time Taken: 2.6785 seconds\n",
      "Epoch: 151/200... Loss: 0.0182... Accuracy: 0.9995... Time Taken: 2.6391 seconds\n",
      "Epoch: 152/200... Loss: 0.0178... Accuracy: 0.9996... Time Taken: 3.2244 seconds\n",
      "Epoch: 153/200... Loss: 0.0180... Accuracy: 0.9996... Time Taken: 3.3582 seconds\n",
      "Epoch: 154/200... Loss: 0.0179... Accuracy: 0.9996... Time Taken: 3.4923 seconds\n",
      "Epoch: 155/200... Loss: 0.0183... Accuracy: 0.9995... Time Taken: 2.5894 seconds\n",
      "Epoch: 156/200... Loss: 0.0177... Accuracy: 0.9996... Time Taken: 2.6014 seconds\n",
      "Epoch: 157/200... Loss: 0.0181... Accuracy: 0.9995... Time Taken: 2.7769 seconds\n",
      "Epoch: 158/200... Loss: 0.0180... Accuracy: 0.9996... Time Taken: 2.6053 seconds\n",
      "Epoch: 159/200... Loss: 0.0177... Accuracy: 0.9996... Time Taken: 2.5928 seconds\n",
      "Epoch: 160/200... Loss: 0.0178... Accuracy: 0.9997... Time Taken: 2.6379 seconds\n",
      "Epoch: 161/200... Loss: 0.0179... Accuracy: 0.9996... Time Taken: 3.1609 seconds\n",
      "Epoch: 162/200... Loss: 0.0177... Accuracy: 0.9997... Time Taken: 2.6448 seconds\n",
      "Epoch: 163/200... Loss: 0.0180... Accuracy: 0.9994... Time Taken: 2.5746 seconds\n",
      "Epoch: 164/200... Loss: 0.0180... Accuracy: 0.9994... Time Taken: 2.6516 seconds\n",
      "Epoch: 165/200... Loss: 0.0182... Accuracy: 0.9994... Time Taken: 3.3428 seconds\n",
      "Epoch: 166/200... Loss: 0.0178... Accuracy: 0.9996... Time Taken: 2.6213 seconds\n",
      "Epoch: 167/200... Loss: 0.0177... Accuracy: 0.9996... Time Taken: 3.0967 seconds\n",
      "Epoch: 168/200... Loss: 0.0178... Accuracy: 0.9996... Time Taken: 2.5412 seconds\n",
      "Epoch: 169/200... Loss: 0.0182... Accuracy: 0.9994... Time Taken: 2.5439 seconds\n",
      "Epoch: 170/200... Loss: 0.0176... Accuracy: 0.9997... Time Taken: 2.5998 seconds\n",
      "Epoch: 171/200... Loss: 0.0176... Accuracy: 0.9996... Time Taken: 2.7536 seconds\n",
      "Epoch: 172/200... Loss: 0.0176... Accuracy: 0.9997... Time Taken: 2.6462 seconds\n",
      "Epoch: 173/200... Loss: 0.0175... Accuracy: 0.9996... Time Taken: 2.6801 seconds\n",
      "Epoch: 174/200... Loss: 0.0176... Accuracy: 0.9996... Time Taken: 2.6599 seconds\n",
      "Epoch: 175/200... Loss: 0.0177... Accuracy: 0.9996... Time Taken: 2.5852 seconds\n",
      "Epoch: 176/200... Loss: 0.0177... Accuracy: 0.9996... Time Taken: 2.6656 seconds\n",
      "Epoch: 177/200... Loss: 0.0176... Accuracy: 0.9996... Time Taken: 2.6122 seconds\n",
      "Epoch: 178/200... Loss: 0.0174... Accuracy: 0.9997... Time Taken: 2.6994 seconds\n",
      "Epoch: 179/200... Loss: 0.0174... Accuracy: 0.9997... Time Taken: 3.3239 seconds\n",
      "Epoch: 180/200... Loss: 0.0176... Accuracy: 0.9995... Time Taken: 2.7048 seconds\n",
      "Epoch: 181/200... Loss: 0.0177... Accuracy: 0.9996... Time Taken: 2.7155 seconds\n",
      "Epoch: 182/200... Loss: 0.0173... Accuracy: 0.9997... Time Taken: 2.5776 seconds\n",
      "Epoch: 183/200... Loss: 0.0173... Accuracy: 0.9995... Time Taken: 2.7194 seconds\n",
      "Epoch: 184/200... Loss: 0.0176... Accuracy: 0.9997... Time Taken: 2.7349 seconds\n",
      "Epoch: 185/200... Loss: 0.0177... Accuracy: 0.9996... Time Taken: 2.5996 seconds\n",
      "Epoch: 186/200... Loss: 0.0175... Accuracy: 0.9997... Time Taken: 2.5958 seconds\n",
      "Epoch: 187/200... Loss: 0.0174... Accuracy: 0.9996... Time Taken: 2.6491 seconds\n",
      "Epoch: 188/200... Loss: 0.0176... Accuracy: 0.9994... Time Taken: 2.5828 seconds\n",
      "Epoch: 189/200... Loss: 0.0172... Accuracy: 0.9998... Time Taken: 3.3346 seconds\n",
      "Epoch: 190/200... Loss: 0.0172... Accuracy: 0.9997... Time Taken: 2.6041 seconds\n",
      "Epoch: 191/200... Loss: 0.0176... Accuracy: 0.9996... Time Taken: 2.6345 seconds\n",
      "Epoch: 192/200... Loss: 0.0174... Accuracy: 0.9996... Time Taken: 2.9950 seconds\n",
      "Epoch: 193/200... Loss: 0.0174... Accuracy: 0.9997... Time Taken: 2.5821 seconds\n",
      "Epoch: 194/200... Loss: 0.0174... Accuracy: 0.9996... Time Taken: 2.7444 seconds\n",
      "Epoch: 195/200... Loss: 0.0177... Accuracy: 0.9996... Time Taken: 2.6246 seconds\n",
      "Epoch: 196/200... Loss: 0.0173... Accuracy: 0.9997... Time Taken: 2.5798 seconds\n",
      "Epoch: 197/200... Loss: 0.0174... Accuracy: 0.9997... Time Taken: 2.6676 seconds\n",
      "Epoch: 198/200... Loss: 0.0172... Accuracy: 0.9997... Time Taken: 3.0055 seconds\n",
      "Epoch: 199/200... Loss: 0.0174... Accuracy: 0.9996... Time Taken: 2.5939 seconds\n",
      "Epoch: 200/200... Loss: 0.0175... Accuracy: 0.9997... Time Taken: 2.6308 seconds\n",
      "Total Time Taken: 559.3997 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "measures = defaultdict(list)\n",
    "start_time = time.time()\n",
    "\n",
    "# put Deep VIB into train mode \n",
    "vib.train()  \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()  \n",
    "    \n",
    "    # exponential decay of learning rate every 2 epochs\n",
    "    if epoch % 2 == 0 and epoch > 0:\n",
    "        scheduler.step()    \n",
    "    \n",
    "    batch_loss = 0\n",
    "    batch_accuracy = 0\n",
    "    for _, (X,y) in enumerate(train_dataloader): \n",
    "        X = X.to(device)        \n",
    "        y = y.long().to(device)\n",
    "        \n",
    "        # Zero accumulated gradients\n",
    "        vib.zero_grad()\n",
    "        \n",
    "        # forward pass through Deep VIB\n",
    "        y_pred, mu, std = vib(X)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_function(y_pred, y, mu, std)\n",
    "        # Backpropogation: calculating gradients\n",
    "        loss.backward()\n",
    "        # Update parameters of generator\n",
    "        optimiser.step()  \n",
    "        \n",
    "        # Save loss per batch\n",
    "        batch_loss += loss.item()*X.size(0) \n",
    "        # Save accuracy per batch\n",
    "        y_pred = torch.argmax(y_pred,dim=1)\n",
    "        batch_accuracy += int(torch.sum(y == y_pred))        \n",
    "           \n",
    "    # Save losses per epoch\n",
    "    measures['total_loss'].append(batch_loss / len(train_dataloader.dataset))        \n",
    "    # Save accuracy per epoch\n",
    "    measures['accuracy'].append(batch_accuracy / len(train_dataloader.dataset))            \n",
    "    \n",
    "    print(\"Epoch: {}/{}...\".format(epoch+1, epochs),\n",
    "          \"Loss: {:.4f}...\".format(measures['total_loss'][-1]),\n",
    "          \"Accuracy: {:.4f}...\".format(measures['accuracy'][-1]),\n",
    "          \"Time Taken: {:,.4f} seconds\".format(time.time()-epoch_start_time))\n",
    "    \n",
    "print(\"Total Time Taken: {:,.4f} seconds\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824... Time Taken: 0.1271 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create DatatLoader \n",
    "test_dataset = data_utils.TensorDataset(x_test, y_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True)\n",
    "\n",
    "measures = defaultdict(int)\n",
    "start_time = time.time()\n",
    "    \n",
    "# put Deep VIB into train mode \n",
    "vib.eval()       \n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, (X,y) in enumerate(test_dataloader): \n",
    "        X = X.to(device)        \n",
    "        y = y.long().to(device)\n",
    "        \n",
    "        # forward pass through Deep VIB\n",
    "        y_pred, mu, std = vib(X)\n",
    "    \n",
    "        y_pred = torch.argmax(y_pred,dim=1)\n",
    "        measures['accuracy'] += int(torch.sum(y == y_pred))\n",
    "\n",
    "print(\"Accuracy: {:.4f}...\".format(measures['accuracy']/len(test_dataloader.dataset)),\n",
    "      \"Time Taken: {:,.4f} seconds\".format(time.time()-start_time))        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
